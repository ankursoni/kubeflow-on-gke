name: Build model
description: Function to build model.
inputs:
- {name: movies}
- {name: unique_user_ids}
- {name: unique_movie_titles}
- {name: train}
- {name: test}
outputs:
- {name: model}
implementation:
  container:
    image: eu.gcr.io/kubeflow-bg-experiment/recommender:latest
    command:
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      def build_model(
          movies_path,
          unique_user_ids_path,
          unique_movie_titles_path,
          train_path,
          test_path,
          model_path,
      ):
          """Function to build model."""
          import pickle
          from typing import Dict, Text

          import tensorflow as tf
          import tensorflow_recommenders as tfrs

          embedding_dimension = 32

          movies = tf.data.Dataset.load(movies_path)

          with open(file=unique_user_ids_path, mode="rb") as f:
              unique_user_ids = pickle.load(f)
          user_model = tf.keras.Sequential(
              [
                  tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),
                  # We add an additional embedding to account for unknown tokens.
                  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),
              ]
          )

          with open(file=unique_movie_titles_path, mode="rb") as f:
              unique_movie_titles = pickle.load(f)
          movie_model = tf.keras.Sequential(
              [
                  tf.keras.layers.StringLookup(
                      vocabulary=unique_movie_titles, mask_token=None
                  ),
                  tf.keras.layers.Embedding(
                      len(unique_movie_titles) + 1, embedding_dimension
                  ),
              ]
          )
          metrics = tfrs.metrics.FactorizedTopK(candidates=movies.batch(128).map(movie_model))
          task = tfrs.tasks.Retrieval(metrics=metrics)

          class MovielensModel(tfrs.Model):
              def __init__(self, user_model, movie_model):
                  super().__init__()
                  self.movie_model: tf.keras.Model = movie_model
                  self.user_model: tf.keras.Model = user_model
                  self.task: tf.keras.layers.Layer = task

              def compute_loss(
                  self, features, training=False
              ):
                  # We pick out the user features and pass them into the user model.
                  user_embeddings = self.user_model(features["user_id"])
                  # And pick out the movie features and pass them into the movie model,
                  # getting embeddings back.
                  positive_movie_embeddings = self.movie_model(features["movie_title"])

                  # The task computes the loss and the metrics.
                  return self.task(user_embeddings, positive_movie_embeddings)

          model = MovielensModel(user_model, movie_model)
          model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))

          train = tf.data.Dataset.load(train_path)
          test = tf.data.Dataset.load(test_path)

          cached_train = train.shuffle(100_000).batch(8192).cache()
          cached_test = test.batch(4096).cache()

          model.fit(cached_train, epochs=3)
          model.evaluate(cached_test, return_dict=True)

          # Create a model that takes in raw query features, and
          index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)
          # recommends movies out of the entire movies dataset.
          index.index_from_dataset(
              tf.data.Dataset.zip(
                  (movies.batch(100), movies.batch(100).map(model.movie_model))
              )
          )

          model.save(f"{model_path}/basic_retrieval_model.h5")

      import argparse
      _parser = argparse.ArgumentParser(prog='Build model', description='Function to build model.')
      _parser.add_argument("--movies", dest="movies_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--unique-user-ids", dest="unique_user_ids_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--unique-movie-titles", dest="unique_movie_titles_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--train", dest="train_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--test", dest="test_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--model", dest="model_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parsed_args = vars(_parser.parse_args())

      _outputs = build_model(**_parsed_args)
    args:
    - --movies
    - {inputPath: movies}
    - --unique-user-ids
    - {inputPath: unique_user_ids}
    - --unique-movie-titles
    - {inputPath: unique_movie_titles}
    - --train
    - {inputPath: train}
    - --test
    - {inputPath: test}
    - --model
    - {outputPath: model}
